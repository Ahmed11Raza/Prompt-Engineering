{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOjPKpNP6CSNs8bi5up2ZnG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ahmed11Raza/Prompt-Engineering/blob/main/Intermidiate_Level_Points.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Intermediate Learning Path Notebook\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "# Intermediate Learning Path\n",
        "This notebook covers the following topics step by step:\n",
        "1. Chain-of-Thought Prompting and In-Depth\n",
        "2. Zero-Shot Chain-of-Thought\n",
        "3. Self-Consistency and In-Depth\n",
        "4. Generated Knowledge\n",
        "5. Prompt Chaining\n",
        "6. Least-to-Most Prompting\n",
        "7. Revisiting Roles\n",
        "8. LLM Settings\n",
        "9. Retrieval Augmented Generation (RAG) and Research Findings\n",
        "\"\"\"\n",
        "\n",
        "# ---\n",
        "# 1. Chain-of-Thought Prompting and In-Depth\n",
        "\"\"\"\n",
        "### What is Chain-of-Thought (CoT) Prompting?\n",
        "CoT is a reasoning technique where the model solves tasks step-by-step.\n",
        "\n",
        "**Practice:**\n",
        "- Ask the model to \"think step by step.\"\n",
        "- Gradually increase complexity.\n",
        "\n",
        "**Example Code:**\n",
        "\"\"\"\n",
        "from transformers import pipeline\n",
        "\n",
        "# Initialize language model\n",
        "generator = pipeline(\"text-generation\", model=\"gpt2\")\n",
        "\n",
        "# Example: Step-by-step reasoning\n",
        "prompt = \"\"\"\n",
        "Q: If Ali has 2 apples and buys 3 more, how many does he have? Think step by step.\n",
        "A:\n",
        "\"\"\"\n",
        "response = generator(prompt, max_length=50, num_return_sequences=1)\n",
        "print(response[0]['generated_text'])\n",
        "\n",
        "# ---\n",
        "# 2. Zero-Shot Chain-of-Thought\n",
        "\"\"\"\n",
        "### What is Zero-Shot CoT?\n",
        "Encourages reasoning without examples.\n",
        "\n",
        "**Practice:**\n",
        "- Use explicit instructions like \"Explain your reasoning step by step.\"\n",
        "- Apply to diverse tasks.\n",
        "\n",
        "**Example Code:**\n",
        "\"\"\"\n",
        "prompt = \"\"\"\n",
        "Explain your reasoning step-by-step: What is the next number in the sequence 2, 4, 8, 16?\n",
        "\"\"\"\n",
        "response = generator(prompt, max_length=50, num_return_sequences=1)\n",
        "print(response[0]['generated_text'])\n",
        "\n",
        "# ---\n",
        "# 3. Self-Consistency and In-Depth\n",
        "\"\"\"\n",
        "### What is Self-Consistency?\n",
        "Generates multiple outputs and selects the most consistent one.\n",
        "\n",
        "**Practice:**\n",
        "- Compare outputs for accuracy.\n",
        "- Useful in workflows needing high precision.\n",
        "\n",
        "**Example Code:**\n",
        "\"\"\"\n",
        "prompt = \"\"\"\n",
        "Generate 3 different step-by-step solutions: If a train leaves at 5 PM and takes 3 hours to reach, when does it arrive?\n",
        "\"\"\"\n",
        "responses = generator(prompt, max_length=50, num_return_sequences=3)\n",
        "for idx, response in enumerate(responses):\n",
        "    print(f\"Solution {idx + 1}: {response['generated_text']}\")\n",
        "\n",
        "# ---\n",
        "# 4. Generated Knowledge\n",
        "\"\"\"\n",
        "### What is Generated Knowledge?\n",
        "It involves creating new knowledge by synthesizing facts.\n",
        "\n",
        "**Practice:**\n",
        "- Use open-ended prompts.\n",
        "- Cross-check generated knowledge for feasibility.\n",
        "\n",
        "**Example Code:**\n",
        "\"\"\"\n",
        "prompt = \"\"\"\n",
        "Based on your knowledge, what would happen if humans could photosynthesize?\n",
        "\"\"\"\n",
        "response = generator(prompt, max_length=50, num_return_sequences=1)\n",
        "print(response[0]['generated_text'])\n",
        "\n",
        "# ---\n",
        "# 5. Prompt Chaining\n",
        "\"\"\"\n",
        "### What is Prompt Chaining?\n",
        "Divides a complex task into smaller sub-tasks.\n",
        "\n",
        "**Practice:**\n",
        "- Start with simple prompts and chain them together.\n",
        "- Example: Write an essay in steps.\n",
        "\n",
        "**Example Code:**\n",
        "\"\"\"\n",
        "# Task 1: Generate an outline\n",
        "outline_prompt = \"Generate an outline for an essay on 'The Importance of Education'.\"\n",
        "outline = generator(outline_prompt, max_length=100, num_return_sequences=1)\n",
        "print(\"Outline:\\n\", outline[0]['generated_text'])\n",
        "\n",
        "# Task 2: Write the introduction based on the outline\n",
        "intro_prompt = f\"Write an introduction for the essay based on the following outline:\\n{outline[0]['generated_text']}\"\n",
        "introduction = generator(intro_prompt, max_length=100, num_return_sequences=1)\n",
        "print(\"\\nIntroduction:\\n\", introduction[0]['generated_text'])\n",
        "\n",
        "# ---\n",
        "# 6. Least-to-Most Prompting\n",
        "\"\"\"\n",
        "### What is Least-to-Most Prompting?\n",
        "Starts with simple tasks and gradually adds complexity.\n",
        "\n",
        "**Practice:**\n",
        "- Add layers incrementally.\n",
        "- Example: Solve a multi-step math problem.\n",
        "\n",
        "**Example Code:**\n",
        "\"\"\"\n",
        "# Step 1\n",
        "step_1 = generator(\"What is 2 + 2?\", max_length=10, num_return_sequences=1)\n",
        "print(\"Step 1:\\n\", step_1[0]['generated_text'])\n",
        "\n",
        "# Step 2\n",
        "step_2 = generator(\"Multiply the result by 3.\", max_length=10, num_return_sequences=1)\n",
        "print(\"Step 2:\\n\", step_2[0]['generated_text'])\n",
        "\n",
        "# ---\n",
        "# 7. Revisiting Roles\n",
        "\"\"\"\n",
        "### What is Revisiting Roles?\n",
        "The model takes on a specific role to tailor responses.\n",
        "\n",
        "**Practice:**\n",
        "- Define clear roles.\n",
        "- Example: A teacher explaining a concept.\n",
        "\n",
        "**Example Code:**\n",
        "\"\"\"\n",
        "role_prompt = \"You are a math teacher. Explain the concept of calculus to a beginner.\"\n",
        "response = generator(role_prompt, max_length=100, num_return_sequences=1)\n",
        "print(response[0]['generated_text'])\n",
        "\n",
        "# ---\n",
        "# 8. LLM Settings\n",
        "\"\"\"\n",
        "### What Are LLM Settings?\n",
        "Control randomness and creativity in responses.\n",
        "\n",
        "**Practice:**\n",
        "- Experiment with temperature (e.g., 0.3 for logical tasks, 0.8 for creative tasks).\n",
        "\n",
        "**Example Code:**\n",
        "\"\"\"\n",
        "# Adjust temperature for creativity\n",
        "creative_response = generator(\"Write a creative story about an AI robot.\", temperature=0.8, max_length=50)\n",
        "logical_response = generator(\"Solve 5 + 7 step by step.\", temperature=0.3, max_length=50)\n",
        "\n",
        "print(\"Creative Output:\\n\", creative_response[0]['generated_text'])\n",
        "print(\"\\nLogical Output:\\n\", logical_response[0]['generated_text'])\n",
        "\n",
        "# ---\n",
        "# 9. Retrieval Augmented Generation (RAG)\n",
        "\"\"\"\n",
        "### What is RAG?\n",
        "Combines external data retrieval with generation.\n",
        "\n",
        "**Practice:**\n",
        "- Integrate APIs or tools for up-to-date data.\n",
        "- Use retrieved data in generation workflows.\n",
        "\n",
        "**Example Code:**\n",
        "\"\"\"\n",
        "# Placeholder for RAG implementation\n",
        "# You would fetch data from APIs or local knowledge bases and pass it to the model\n",
        "retrieved_data = \"Latest research on AI ethics emphasizes the importance of transparency.\"\n",
        "prompt = f\"Using the following data: {retrieved_data}, summarize key challenges in AI ethics.\"\n",
        "response = generator(prompt, max_length=100, num_return_sequences=1)\n",
        "print(response[0]['generated_text'])\n",
        "\n",
        "\"\"\"\n",
        "# Conclusion\n",
        "This notebook introduces intermediate-level techniques for reasoning, creativity, and task management using language models. Modify and experiment with the provided examples to deepen your understanding.\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "0YRQeChnqhMx"
      }
    }
  ]
}